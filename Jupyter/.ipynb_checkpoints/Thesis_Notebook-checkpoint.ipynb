{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916517d4-ead6-4045-bc1d-9bc69fcdba5c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a1238-3171-422d-b2ed-1f7333b1c529",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19815ebd-ff55-451b-9874-cb7c54b16ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_rel\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import ast\n",
    "from prince import MCA\n",
    "from matplotlib import cm\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.color_palette(\"rocket\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1254cc-eb4a-4fd8-8d27-92ae193177c3",
   "metadata": {},
   "source": [
    "# LLN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8a6da-54ca-42d5-b57e-e932401b8cd5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10f88c-0769-452f-8368-5300f70f6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"files/Thesis_Files/LLN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7b848-b20d-4e09-b756-55d275776d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Probability\n",
    "values = [4, 10, 350, 1000, 10000, 50000, 100000, 1000000]\n",
    "weighted_tests = dict()\n",
    "for v in values:\n",
    "    weighted_tests[v] = pd.read_csv(f'{dir_path}/LLN_Test_{v}.csv', header=0)\n",
    "\n",
    "alt_tests = dict()\n",
    "for v in values:\n",
    "    alt_tests[v] = pd.read_csv(f'{dir_path}/LLN_Test_{v}_alt.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46c7f9-4051-49c8-9068-7395b3721265",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f60d8-94b0-42e4-93cc-ee274f9690df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prob_plot(title, dictionary, value):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Group by 'Sort' column and count elements in each group\n",
    "    group_counts = dictionary[value].groupby('Sort').size()\n",
    "    \n",
    "    # Plotting\n",
    "    my_sum = sum(group_counts.values)\n",
    "    plt.bar(group_counts.index, (group_counts.values)/my_sum)\n",
    "    ax.set_xlabel('Topological Sort')\n",
    "    ax.set_ylabel('Probability of Topological Sort')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    for i, count in enumerate(group_counts):\n",
    "        ax.text(i, count/my_sum, str(round(count/my_sum,3)), ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a8b94-8788-4145-a0fe-a1c8d2b59685",
   "metadata": {},
   "source": [
    "### Probabilistic Kahn's with Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6544105-2c2f-4e42-87f3-ce98ea9fa777",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 4 Test\", weighted_tests, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c89215-a185-4110-a3c9-cd74ed5e834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 10 Test\", weighted_tests, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35683445-a7f4-45be-8b88-630c32b7a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 350 Test\", weighted_tests, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1267ea0-3e82-4116-b2fa-5b6dee1606d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 1000 Test\", weighted_tests, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a588a2-1ec2-4198-a49a-d62fdb1c29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 10000 Test\", weighted_tests, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e130342-4098-4015-b983-8603bb19520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 50000 Test\", weighted_tests, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb2dc7-b093-4106-ae96-b95f557c93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 100000 Test\", weighted_tests, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfce23-3c61-45ef-b7a2-00d56fb90b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 1000000 Test\", weighted_tests, 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d73350-fe65-4a4c-a6b6-ca5da336c51d",
   "metadata": {},
   "source": [
    "### Probabilistic Kahn's without Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672344a-a534-49be-8f7b-b29a0695b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 4 Test - Alt\", alt_tests, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468c707-d3d9-4bcb-8110-0b0a78d78204",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 10 Test - Alt\", alt_tests, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3af5cb-9efc-457b-b6bf-9267659cfe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 350 Test - Alt\", alt_tests, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f768712-06a0-4121-aef8-af445b835241",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 1000 Test - Alt\", alt_tests, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa7f25-4471-4ce3-ad0e-87c041f541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 10000 Test - Alt\", alt_tests, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c3652-49eb-4092-8c98-29b2163eb2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 50000 Test - Alt\", alt_tests, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67504e-1cb6-441f-a385-ac354efc28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 100000 Test - Alt\", alt_tests, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017e92a-ae8c-4ba3-a62b-c64445583a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_prob_plot(\"Law of Large Numbers - 1000000 Test - Alt\", alt_tests, 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7420c2-dca0-4b50-8cf9-45b663714f14",
   "metadata": {},
   "source": [
    "# Flag Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79a8c5-abe3-49fa-9e97-3cac66992543",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44f32b-ebbd-4f51-8d9a-8a1a94f933f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"files/Thesis_Files/flag_selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd4d1a-dc25-49db-80e7-2d69a1b50b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cacheprof_BOCA = pd.read_csv(f\"{dir_path}/cacheprof-BOCA-FlagSelection_new-0.csv\", index_col=[0])\n",
    "# cacheprof_GA = pd.read_csv(f\"{dir_path}/cacheprof-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "# hidden_BOCA = pd.read_csv(f\"{dir_path}/hidden-BOCA-FlagSelection_new-0.csv\", index_col=[0])\n",
    "# hidden_GA = pd.read_csv(f\"{dir_path}/hidden-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "# maillist_BOCA = pd.read_csv(f\"{dir_path}/maillist-BOCA-FlagSelection_new-0.csv\", index_col=[0])\n",
    "# maillist_GA = pd.read_csv(f\"{dir_path}/maillist-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "# sorting_BOCA = pd.read_csv(f\"{dir_path}/sorting-BOCA-FlagSelection_new-0.csv\", index_col=[0])\n",
    "# sorting_GA = pd.read_csv(f\"{dir_path}/sorting-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "cacheprof_BOCA = pd.read_csv(f\"{dir_path}/cacheprof-BOCA-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "cacheprof_GA = pd.read_csv(f\"{dir_path}/cacheprof-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "hidden_BOCA = pd.read_csv(f\"{dir_path}/hidden-BOCA-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "hidden_GA = pd.read_csv(f\"{dir_path}/hidden-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "maillist_BOCA = pd.read_csv(f\"{dir_path}/maillist-BOCA-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "maillist_GA = pd.read_csv(f\"{dir_path}/maillist-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "sorting_BOCA = pd.read_csv(f\"{dir_path}/sorting-BOCA-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "sorting_GA = pd.read_csv(f\"{dir_path}/sorting-Genetic-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "\n",
    "# Iterative Ones\n",
    "cacheprof_RIO =  pd.read_csv(f\"{dir_path}/cacheprof-Iterative-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "for i in range(1,20):\n",
    "    cacheprof_RIO = pd.concat([cacheprof_RIO, pd.read_csv(f\"{dir_path}/cacheprof-Iterative-Second_Final_DataCollect-{i}.csv\", index_col=[0])])\n",
    "cacheprof_RIO.drop_duplicates(subset=[\"ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "maillist_RIO =  pd.read_csv(f\"{dir_path}/maillist-Iterative-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "for i in range(1,20):\n",
    "    cacheprof_RIO = pd.concat([cacheprof_RIO, pd.read_csv(f\"{dir_path}/maillist-Iterative-Second_Final_DataCollect-{i}.csv\", index_col=[0])])\n",
    "cacheprof_RIO.drop_duplicates(subset=[\"ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "hidden_RIO =  pd.read_csv(f\"{dir_path}/hidden-Iterative-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "for i in range(1,20):\n",
    "    cacheprof_RIO = pd.concat([cacheprof_RIO, pd.read_csv(f\"{dir_path}/hidden-Iterative-Second_Final_DataCollect-{i}.csv\", index_col=[0])])\n",
    "cacheprof_RIO.drop_duplicates(subset=[\"ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "sorting_RIO =  pd.read_csv(f\"{dir_path}/sorting-Iterative-Second_Final_DataCollect-0.csv\", index_col=[0])\n",
    "for i in range(1,20):\n",
    "    sorting_RIO = pd.concat([sorting_RIO, pd.read_csv(f\"{dir_path}/sorting-Iterative-Second_Final_DataCollect-{i}.csv\", index_col=[0])])\n",
    "sorting_RIO.drop_duplicates(subset=[\"ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "program_tables = {\"maillist\": {\"BOCA\": maillist_BOCA, \"GA\": maillist_GA, \"RIO\": maillist_RIO}, \"hidden\": {\"BOCA\": hidden_BOCA, \"GA\": hidden_GA, \"RIO\": hidden_RIO}, \"cacheprof\": {\"BOCA\": cacheprof_BOCA, \"GA\": cacheprof_GA, \"RIO\": cacheprof_RIO}, \"sorting\": {\"BOCA\": sorting_BOCA, \"GA\": sorting_GA, \"RIO\": sorting_RIO}}\n",
    "\n",
    "for d in program_tables.values():\n",
    "    for d_name, df in d.items():\n",
    "        if not (df is None):\n",
    "            df.set_index(\"ID\", inplace=True)\n",
    "\n",
    "\n",
    "for d_name, d in program_tables.items():\n",
    "    for type, t in d.items():\n",
    "        if type == \"GA\":\n",
    "            t.rename(columns={'Fitness': 'Runtime'}, inplace=True)\n",
    "\n",
    "print(program_tables[\"cacheprof\"][\"GA\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757f5b7-7007-4e52-9d83-a81d101076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [\"-fcall-arity\", \"-fcase-merge\", \"-fcmm-elim-common-blocks\", \"-fcmm-sink\", \"-fcpr-anal\", \"-fcse\",\"-fdicts-cheap\", \"-fdicts-strict\", \"-fdmd-tx-dict-sel\", \"-fdo-eta-reduction\", \"-fdo-lambda-eta-expansion\",\"-feager-blackholing\", \"-fenable-rewrite-rules\", \"-fexcess-precision\", \"-fexpose-all-unfoldings\",\"-ffloat-in\", \"-ffull-laziness\", \"-ffun-to-thunk\", \"-fignore-asserts\", \"-fignore-interface-pragmas\",\"-flate-dmd-anal\", \"-fliberate-case\", \"-fliberate-case-threshold=2000\", \"-floopification\", \"-fmax-inline-alloc-size=128\",\"-fmax-inline-memcpy-insns=32\", \"-fmax-inline-memset-insns=32\", \"-fmax-relevant-binds=6\", \"-fmax-simplifier-iterations=4\",\"-fmax-worker-args=10\", \"-fno-opt-coercion\", \"-fno-pre-inlining\", \"-fno-state-hack\", \"-fomit-interface-pragmas\", \"-fomit-yields\",\"-foptimal-applicative-do\", \"-fpedantic-bottoms\", \"-fregs-graph\", \"-fregs-iterative\", \"-fsimplifier-phases=2\", \"-fsimpl-tick-factor=100\",\"-fspec-constr\", \"-fspec-constr-count=3\", \"-fspec-constr-threshold=2000\", \"-fspecialise\", \"-fcross-module-specialise\", \"-fstatic-argument-transformation\",\"-fstrictness\", \"-fstrictness-before=1\", \"-funbox-small-strict-fields\", \"-funbox-strict-fields\", \"-funfolding-creation-threshold=750\",\"-funfolding-dict-discount=30\", \"-funfolding-fun-discount=60\", \"-funfolding-keeness-factor=1.5\", \"-funfolding-use-threshold=60\",\"-fvectorisation-avoidance\", \"-fvectorise\", \"-fworker-wrapper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f38166-a49b-42fe-86fa-6aa68a3b87e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6309b1b-2988-4183-850a-6a42f1774c96",
   "metadata": {},
   "source": [
    "### Get Best Rows & Update Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de7074-d714-4db3-9082-8a9b13f8b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new dictionary to store the updated values\n",
    "updated_program_tables = dict()\n",
    "for program, config_dict in program_tables.items():\n",
    "    updated_config_dict = dict()\n",
    "    \n",
    "    for config, dataframe in config_dict.items():\n",
    "        if dataframe is not None:\n",
    "            # Extract rows by index\n",
    "            #print(dataframe.head(4))\n",
    "            row_O0 = dataframe.loc[\"-O0\"]\n",
    "            row_O2 = dataframe.loc[\"-O2\"]\n",
    "            # Find the row with the minimum \"Runtime\" value\n",
    "            best_row = dataframe.loc[dataframe[\"Runtime\"].idxmin()]\n",
    "            \n",
    "            # Create the new dictionary for the current configuration\n",
    "            updated_config = {\n",
    "                \"table\": dataframe,\n",
    "                \"-O0\": row_O0,\n",
    "                \"-O2\": row_O2,\n",
    "                \"Best\": best_row\n",
    "            }\n",
    "            \n",
    "            updated_config_dict[config] = updated_config\n",
    "    \n",
    "    updated_program_tables[program] = updated_config_dict\n",
    "# Now, `updated_program_tables` contains the updated dictionary as you specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbb7b0-1b07-495b-ae47-9e3fa0def03f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c3ec9-a0d9-48a9-803e-db87b5e9e3c1",
   "metadata": {},
   "source": [
    "### Table: -O0 vs. -O2 vs. Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a584a-d473-4705-83c9-43025efbbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `updated_program_tables` contains your updated dictionary\n",
    "data = []\n",
    "programs = list(updated_program_tables.keys())\n",
    "configurations = [\"BOCA\", \"GA\", \"RIO\"]\n",
    "columns = [\"-O0\", \"-O2\", \"Optimal\", \"Improvement\", \"Avg\"]\n",
    "\n",
    "for program in programs:\n",
    "    program_data = []\n",
    "    row_O0s = []\n",
    "    row_O2s = []\n",
    "    for config in configurations:\n",
    "        if updated_program_tables[program][config] is not None:\n",
    "            row_O0 = updated_program_tables[program][config][\"-O0\"][\"Runtime\"]\n",
    "            row_O2 = updated_program_tables[program][config][\"-O2\"][\"Runtime\"]\n",
    "            best_row = updated_program_tables[program][config][\"Best\"][\"Runtime\"]\n",
    "            improvement = f\"{round(-1*(1 - best_row/row_O2)*100,3)}%\"\n",
    "            average = f\"{round(-1*(1 - program_tables[program][config]['Runtime'].mean()/row_O2)*100,3)}%\"\n",
    "            program_data.append([row_O0, row_O2, best_row, improvement, average])\n",
    "            row_O0s.append(row_O0)\n",
    "            row_O2s.append(row_O2)\n",
    "        else:\n",
    "            program_data.append([None, None, None])\n",
    "    data.extend(program_data)\n",
    "    for config in configurations:\n",
    "        updated_program_tables[program][config][\"-O0\"][\"Runtime\"] = round(np.mean(row_O0s),3)\n",
    "        updated_program_tables[program][config][\"-O2\"][\"Runtime\"] = round(np.mean(row_O2s),3)\n",
    "\n",
    "# Create a MultiIndex with program and configuration levels\n",
    "index = pd.MultiIndex.from_product([programs, configurations], names=[\"Program\", \"Configuration\"])\n",
    "\n",
    "# Reshape data into a DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Assign the MultiIndex\n",
    "df.index = index\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4eaf6-db96-4541-bca6-13e4d30321f6",
   "metadata": {},
   "source": [
    "### Box-Plots to Show Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558962e-cf5e-4f21-9f92-a0ec78141592",
   "metadata": {},
   "source": [
    "#### Normalization Calculation Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2bf40-4214-4b0e-8030-009c4a7a62db",
   "metadata": {},
   "source": [
    "##### -O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223f5b7-5df9-4f32-9b0f-4376fb92dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_around = \"-O2\"\n",
    "\n",
    "for program, config_dict in updated_program_tables.items():\n",
    "    for config, table_data in config_dict.items():\n",
    "        if table_data is not None:\n",
    "            df = table_data[\"table\"]\n",
    "            df[\"Norm-Z\"] = (df[\"Runtime\"] - df[\"Runtime\"].mean()) / df[\"Runtime\"].std()\n",
    "            row_O0 = df.loc[\"-O0\"]\n",
    "            row_O2 = df.loc[\"-O2\"]\n",
    "            shift = row_O2[\"Runtime\"]\n",
    "            df[\"Norm-O2\"] = (df[\"Runtime\"] - shift) / df[\"Runtime\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40729818-1859-471d-b67e-c3aadb8ff9f6",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0623f-4b8c-42cb-b213-b51edb17f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "lst1 = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for program_name, type_dict in updated_program_tables.items():\n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    for type_name, type_results in type_dict.items():\n",
    "        if type_name != \"IO\":\n",
    "            labels.append(type_name)\n",
    "            df = type_results[\"table\"]\n",
    "            lst1.append(df[\"Norm-Z\"])\n",
    "    # if i == 2:\n",
    "    #     i = 0\n",
    "    #     if j == 2:\n",
    "    #         j == 0\n",
    "    #     else:\n",
    "    #         j += 1\n",
    "    # i += 1\n",
    "    ax[i][j].boxplot(lst1)\n",
    "    ax[i][j].set_xticklabels(labels, fontsize=\"xx-small\")\n",
    "    ax[i][j].set_ylabel(f\"Normalized Z-Score Runtime Distribution\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_xlabel(f\"Type of Optimization\", fontsize=\"x-small\")\n",
    "    if i ==  0:\n",
    "        ax[i][j].set_title(f\"{program_name}\", pad=20)\n",
    "    ax[i][j].set_title(f\"{program_name}\", fontsize=\"small\")\n",
    "    \n",
    "    j = (j + 1) % 2\n",
    "    if j == 0:\n",
    "        i = (i + 1) % 2\n",
    "\n",
    "plt.savefig('thesis_figures/Z_score_boxplot.svg', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124300f-768f-43d2-900f-2309178c0ad7",
   "metadata": {},
   "source": [
    "#### -O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa093316-d935-49d6-912b-58095b6b6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "lst1 = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for program_name, type_dict in updated_program_tables.items():\n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    O0_line = 0\n",
    "    for type_name, type_results in type_dict.items():\n",
    "        labels.append(type_name)\n",
    "        df = type_results[\"table\"]\n",
    "        #print(df[\"Norm-O2\"].head(4))\n",
    "        O0_line = df.loc[\"-O0\"][\"Norm-O2\"]\n",
    "        lst1.append(df[\"Norm-O2\"])\n",
    "\n",
    "\n",
    "    \n",
    "    ax[i][j].boxplot(lst1)\n",
    "    ax[i][j].set_xticklabels(labels, fontsize=\"xx-small\")\n",
    "    ax[i][j].set_ylabel(f\"Normalized -O2 Runtime Distribution\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_xlabel(f\"Type of Optimization\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_title(f\"{program_name}\", fontsize=\"small\")\n",
    "\n",
    "    ax[i][j].hlines(y=O0_line, xmin=0, xmax=len(labels) + 1, color='b', linestyle='dashed', linewidth=2)\n",
    "    ax[i][j].text(len(labels) + 1.1, O0_line, '-O0', fontsize='xx-small', color='b')\n",
    "    \n",
    "    j = (j + 1) % 2\n",
    "    if j == 0:\n",
    "        i = (i + 1) % 2\n",
    "\n",
    "plt.savefig('thesis_figures/O2_score_boxplot.svg', format='svg', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91d196-e1bf-4f10-976d-175b51cf554f",
   "metadata": {},
   "source": [
    "### Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f81301-b238-4fcd-905e-f331966fe333",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "occuring_flags = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "convergence_dict = dict()\n",
    "for program_name, type_dict in updated_program_tables.items():\n",
    "    occuring_flags = []\n",
    "    labels = []\n",
    "    for type_name, type_results in type_dict.items():\n",
    "        if type_name != \"RIO\":\n",
    "            best_flags = type_results[\"Best\"][\"Flags\"]\n",
    "            best_flags = eval(best_flags)[1:]\n",
    "            occuring_flags.append(best_flags)\n",
    "            labels.append(type_name)\n",
    "            \n",
    "    if len(occuring_flags) > 0:\n",
    "        num_of_match = list(set(occuring_flags[0]).intersection(set(occuring_flags[1])))\n",
    "        convergence_dict[program_name] = {labels[0]: len(occuring_flags[0]), labels[1]: len(occuring_flags[1]), \"Both\": len(num_of_match)}\n",
    "\n",
    "programs = list(convergence_dict.keys())\n",
    "configurations = list(convergence_dict[\"sorting\"].keys())\n",
    "values = np.array([[convergence_dict[program][config] for program in programs] for config in configurations])\n",
    "\n",
    "print(values)\n",
    "\n",
    "width = 0.25\n",
    "x = np.arange(len(programs))\n",
    "\n",
    "for i, config in enumerate(configurations):\n",
    "    ax.bar(x + i * width, values[i], width=width, label=config)\n",
    "\n",
    "ax.set_xlabel('Program', fontsize=\"medium\", weight='bold')\n",
    "ax.set_ylabel('Number of Shared Flags', fontsize=\"medium\", weight='bold')\n",
    "ax.set_title('Number of Shared Flags between BOCA & GA Optimal Results', fontsize=\"large\", weight='bold')\n",
    "ax.set_xticks(x + width * (len(configurations) - 1) / 2)\n",
    "ax.set_xticklabels(programs, fontsize=\"xx-small\", weight='bold')\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "\n",
    "print(convergence_dict)\n",
    "\n",
    "plt.savefig('thesis_figures/converg_barplot.svg', format='svg', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37338f8-2b36-4962-8280-2ac62483c7f6",
   "metadata": {},
   "source": [
    "### Remaining Benchmark Allowance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ab39c-64a7-49db-bcb8-d9803c1fdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "programs = [\"Maillist\", \"Hidden\", \"Cacheprof\", \"Sorting\"]\n",
    "ml_models = [\"BOCA\", \"GA\", \"RIO\"]\n",
    "boca_data = [2568, 2568, 2568, 2568]\n",
    "ga_data = [3211, 3232, 3238, 3280]\n",
    "rio_data = [10000, 10000, 10000, 10000]\n",
    "\n",
    "data_list = [boca_data, ga_data, rio_data]\n",
    "\n",
    "width = 0.25\n",
    "x = np.arange(len(programs))\n",
    "\n",
    "for i, config in enumerate(data_list):\n",
    "    ax.bar(x + i * width, config[i], width=width, label=ml_models[i])\n",
    "\n",
    "    for j, value in enumerate(config):\n",
    "        ax.text(x[j] + i * width, value + 50, str(value), ha='center', va='bottom', fontsize=\"x-small\")\n",
    "\n",
    "ax.set_xlabel('Program', fontsize=\"medium\", weight='bold')\n",
    "ax.set_ylabel('Allowance Used', fontsize=\"medium\", weight='bold')\n",
    "ax.set_title('Benchmark Allowance Used by each Machine Learning Model', fontsize=\"large\", weight='bold')\n",
    "ax.set_xticks(x + width * (len(configurations) - 1) / 2)\n",
    "ax.set_yticks(np.arange(0, max(max(data_list)) + 1000, 1000))\n",
    "ax.set_xticklabels(programs, fontsize=\"x-small\", weight='bold')\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "\n",
    "\n",
    "plt.savefig('thesis_figures/allowance_plot.svg', format='svg', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7a9f3-e90f-45b3-834d-945bb58c1e21",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb34f3e-ef7c-4c5d-bc6a-76aaa3510861",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PCA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be406d-d69b-429f-b8cd-b15db342435d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f46adf-e4da-43c7-a28f-b23a4685f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_tables = program_tables.copy()\n",
    "\n",
    "feature_df = pd.DataFrame(columns=flags + [\"Runtime\"])\n",
    "scaled_data = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for program_name, config_dict in program_tables.items():\n",
    "    for config, df in config_dict.items():\n",
    "        df = df.iloc[2:]\n",
    "        df[\"Flags\"] = df[\"Flags\"].apply(ast.literal_eval)\n",
    "        new_rows = []\n",
    "        for index, row in df.iterrows():\n",
    "            # Initialize a list to hold flag values for this row\n",
    "            flag_values = [0] * len(flags)\n",
    "            \n",
    "            # Iterate through each flag in the row\n",
    "            #print(row['Flags'])\n",
    "            for index, flag in enumerate(row.Flags):\n",
    "                # Find the index of the flag in my_flags and set the corresponding value to 1\n",
    "                if flag in flags:\n",
    "                    flag_values[flags.index(flag)] = 1\n",
    "                \n",
    "            # Append the row to the new DataFrame with flag values and Runtime\n",
    "            new_rows.append(flag_values + [None])\n",
    "        scaling=StandardScaler()\n",
    "        scaling.fit(np.array(df[\"Runtime\"]).reshape(-1, 1))\n",
    "        scaled_data=scaling.transform(np.array(df[\"Runtime\"]).reshape(-1, 1))\n",
    "        for index, row in enumerate(new_rows):\n",
    "            row[len(row) - 1] = scaled_data[index][0]\n",
    "        new_df = pd.DataFrame(columns=feature_df.columns, data=new_rows)\n",
    "        feature_df = pd.concat([feature_df, new_df], axis=0)\n",
    "        \n",
    "\n",
    "# scaling=StandardScaler()\n",
    " \n",
    "# # Use fit and transform method \n",
    "# scaling.fit(np.array(feature_df[\"Runtime\"]).reshape(-1, 1))\n",
    "# scaled_data=scaling.transform(np.array(feature_df[\"Runtime\"]).reshape(-1, 1))\n",
    "\n",
    "feature_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f777644-4168-4751-b93b-78b5a1c59f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df[feature_df[\"-fcall-arity\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b04467-54a7-4d0a-8c6a-408a702f44c0",
   "metadata": {},
   "source": [
    "#### PCA Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243913b-8f8c-4e63-9c05-1e764f77a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal = PCA(n_components=3)\n",
    "principal.fit(feature_df.drop(\"Runtime\",axis=1))\n",
    "x = principal.transform(feature_df.drop(\"Runtime\",axis=1))\n",
    " \n",
    "# Check the dimensions of data after PCA\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf4858-9cfd-44cb-9455-16f91da9f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8447258-6a38-4e7d-be35-5a7f1f5e8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x[:,0],x[:,1],c=feature_df['Runtime'],cmap='plasma')\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "plt.savefig('thesis_figures/PCA_2d_plot.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988440f-b44d-423c-bcf7-4f7771bc7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    " \n",
    "# choose projection 3d for creating a 3d graph\n",
    "axis = fig.add_subplot(111, projection='3d')\n",
    " \n",
    "# x[:,0]is pc1,x[:,1] is pc2 while x[:,2] is pc3\n",
    "axis.scatter(x[:,0],x[:,1],x[:,2], c=feature_df['Runtime'],cmap='plasma')\n",
    "axis.set_xlabel(\"PC1\", fontsize=10)\n",
    "axis.set_ylabel(\"PC2\", fontsize=10)\n",
    "axis.set_zlabel(\"PC3\", fontsize=10)\n",
    "plt.savefig('thesis_figures/PCA_3d_plot.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdd22b-a629-4ec7-8d2d-dd54f45ada33",
   "metadata": {},
   "source": [
    "#### Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3f0fe-3e29-4785-aae8-e53f34e39566",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_values = np.arange(principal.n_components_) + 1\n",
    "plt.plot(PC_values, principal.explained_variance_ratio_, 'ro-', linewidth=2, color=\"blue\")\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e227e-24d1-42b5-9d54-b86cc6e9fb58",
   "metadata": {},
   "source": [
    "#### Loading Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bb013-93a6-4556-abd4-a17468840bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loadings\n",
    "loadings = principal.components_.T * np.sqrt(principal.explained_variance_)\n",
    "\n",
    "# Plot loadings\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, feature in enumerate(feature_df.drop(\"Runtime\",axis=1).columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], head_width=0.1, head_length=0.1, color='r')\n",
    "    plt.text(loadings[i, 0]*1.1, loadings[i, 1]*1.1, feature, color='g', ha='center', va='center')\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.title('PCA Loading Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b84bc2-db64-4733-be97-c1cc98eced3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74befb1-2e4a-4f14-8256-4a6bcebbdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_df.columns:\n",
    "    feature_df[col] = pd.to_numeric(feature_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce303cf0-6f50-40f7-be59-a24575e63d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = MCA(n_components=2)\n",
    "mca.fit(feature_df.drop(\"Runtime\",axis=1))\n",
    "print(\"Eigenvalues:\")\n",
    "print(mca.eigenvalues_)\n",
    "\n",
    "# # Principal inertia\n",
    "# print(\"Principal Inertia:\")\n",
    "# print(mca.explained_inertia_)\n",
    "\n",
    "# Transformed data\n",
    "print(\"Transformed Data:\")\n",
    "transformed_data = mca.transform(feature_df.drop(\"Runtime\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c297eb-eeb5-4c9a-b58c-f79c7a737ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccb14a-090c-42c7-9bd5-3e4bc279421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row and column coordinates (normalized singular values) after fitting\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "column_coordinates = mca.column_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "\n",
    "# Calculate the variance explained by each feature after using 6 components\n",
    "variance_explained_by_feature = (column_coordinates ** 2).sum(axis=1)\n",
    "\n",
    "# Sort the features based on their contribution to the variance\n",
    "top_features = variance_explained_by_feature.sort_values(ascending=False)\n",
    "\n",
    "# Print the top 6 features\n",
    "print(\"Top 6 features contributing the most to the variance after using 6 components:\")\n",
    "print(top_features.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd822d5-c02a-490f-a88e-df55dd9ac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.column_contributions_.style.format('{:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ca591-9706-432d-8909-687263472bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "row_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7706ee-579a-4a1b-87a6-f0453b82711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style with a warm and nuanced color palette\n",
    "sns.set(style=\"whitegrid\", palette=\"rocket\")\n",
    "\n",
    "# Get the row coordinates (coordinates of categories) for the first two components\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\", axis=1))\n",
    "\n",
    "# Plot the row coordinates on a scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot points for Component 0 with circles\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][0:len(row_coordinates)//2], \n",
    "                y=row_coordinates.iloc[:, 1][0:len(row_coordinates)//2], \n",
    "                alpha=0.7, label='Component 0', marker='o')\n",
    "\n",
    "# Plot points for Component 1 with squares\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][len(row_coordinates)//2:], \n",
    "                y=row_coordinates.iloc[:, 1][len(row_coordinates)//2:], \n",
    "                alpha=0.7, label='Component 1', marker='s')\n",
    "\n",
    "plt.title('MCA Plot of Components')\n",
    "plt.xlabel('Component 0')\n",
    "plt.ylabel('Component 1')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.savefig('thesis_figures/MCA_2d_plot.svg', format='svg', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47263295-862a-455f-aefe-635a61f06e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute feature coordinates (loadings)\n",
    "# feature_coordinates = mca.column_coordinates(feature_df.drop(\"Runtime\", axis=1))\n",
    "\n",
    "# # Set seaborn style\n",
    "# # sns.set()\n",
    "\n",
    "# # Plot row coordinates (loadings)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.scatterplot(x=row_coordinates.iloc[:, 0], y=row_coordinates.iloc[:, 1], color='blue')\n",
    "# plt.xlabel('Dimension 1')\n",
    "# plt.ylabel('Dimension 2')\n",
    "# plt.title('MCA Loading Plot')\n",
    "\n",
    "# # Plot arrows for feature loadings\n",
    "# for i, feature in enumerate(feature_df.drop(\"Runtime\", axis=1).columns):\n",
    "#     plt.arrow(0, 0, feature_coordinates.iloc[i, 0], feature_coordinates.iloc[i, 1], color='red', width=0.01, head_width=0.05)\n",
    "#     plt.text(feature_coordinates.iloc[i, 0]*1.1, feature_coordinates.iloc[i, 1]*1.1, feature, color='red')\n",
    "\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cbebd-6855-428a-94f5-8823d4e52c82",
   "metadata": {},
   "source": [
    "# Phase-Order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fa0aa-28b9-44da-8e5c-52c977ca4abd",
   "metadata": {},
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579b951-40bc-461b-a986-0b4d9f600c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "sns.color_palette(\"rocket\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38880bcf-e426-4b86-b542-eaa29e3829b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"files/Thesis_Files/phase_order\"\n",
    "phase_data_path = \"../Python/phase_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abbb8b-ae2b-4e38-b312-ab9416d62d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase Data Import\n",
    "phase_data = pd.read_csv(f\"{phase_data_path}\", header=0)\n",
    "\n",
    "# RIO Test Results\n",
    "cacheprof_RIO = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "sorting_RIO = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "maillist_RIO = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "hidden_RIO = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-0.csv\", index_col=[0])\n",
    "\n",
    "# BOCA Test Results\n",
    "# cacheprof_BOCA = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Boca_Presentation_Thesis_Test_4Program-0.csv\", index_col=[0])\n",
    "# sorting_BOCA = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Boca_Presentation_Thesis_Test_4Program-0.csv\", index_col=[0])\n",
    "# maillist_BOCA = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Boca_Presentation_Thesis_Test_4Program-0.csv\", index_col=[0])\n",
    "# hidden_BOCA = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Boca_Presentation_Thesis_Test_4Program-0.csv\", index_col=[0])\n",
    "cacheprof_BOCA = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-BOCA_Test_4Program_04-27-2024-0.csv\", index_col=[0])\n",
    "sorting_BOCA = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-BOCA_Test_4Program_04-27-2024-0.csv\", index_col=[0])\n",
    "maillist_BOCA = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-BOCA_Test_4Program_04-27-2024-0.csv\", index_col=[0])\n",
    "hidden_BOCA = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-BOCA_Test_4Program_04-27-2024-0.csv\", index_col=[0])\n",
    "\n",
    "# Control Group (O2 In Default Order)\n",
    "cacheprof_default = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-Iterative-BIGRIO-0.csv\", index_col=[0])\n",
    "hidden_default = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-Iterative-PHASEORDERRIO-0.csv\", index_col=[0])\n",
    "maillist_default =  pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-Iterative-PHASEORDERRIO-0.csv\", index_col=[0])\n",
    "sorting_default = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-Iterative-PHASEORDERRIO-0.csv\", index_col=[0])\n",
    "\n",
    "# Add additional RIO Results\n",
    "for i in range(1,4):\n",
    "    cacheprof_RIO = pd.concat([cacheprof_RIO, pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-{i}.csv\", index_col=[0])])\n",
    "    sorting_RIO= pd.concat([sorting_RIO, pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-{i}.csv\", index_col=[0])])\n",
    "    maillist_RIO = pd.concat([maillist_RIO, pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-{i}.csv\", index_col=[0])])\n",
    "    hidden_RIO = pd.concat([hidden_RIO, pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-Iterative-Flag_Selection_MultiProgram_Test_4Program-{i}.csv\", index_col=[0])])\n",
    "\n",
    "\n",
    "# # New Slow + Fast Rule:\n",
    "cacheprof_special = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Special-Rule-Thesis-10p-0.csv\", index_col=[0])\n",
    "hidden_special = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Special-Rule-Thesis-10p-0.csv\", index_col=[0])\n",
    "maillist_special = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Special-Rule-Thesis-10p-0.csv\", index_col=[0])\n",
    "sorting_special = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Special-Rule-Thesis-10p-0.csv\", index_col=[0])\n",
    "\n",
    "cacheprof_special_5p = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Special-Rule-Thesis-5p-0.csv\", index_col=[0])\n",
    "hidden_special_5p = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Special-Rule-Thesis-5p-0.csv\", index_col=[0])\n",
    "maillist_special_5p = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Special-Rule-Thesis-5p-0.csv\", index_col=[0])\n",
    "sorting_special_5p = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Special-Rule-Thesis-5p-0.csv\", index_col=[0])\n",
    "\n",
    "cacheprof_special_1p = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Special-Rule-Thesis-1p-0.csv\", index_col=[0])\n",
    "hidden_special_1p = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Special-Rule-Thesis-1p-0.csv\", index_col=[0])\n",
    "maillist_special_1p = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Special-Rule-Thesis-1p-0.csv\", index_col=[0])\n",
    "sorting_special_1p = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Special-Rule-Thesis-1p-0.csv\", index_col=[0])\n",
    "\n",
    "\n",
    "cacheprof_special_005p = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Special-Rule-Thesis-005p-0.csv\", index_col=[0])\n",
    "hidden_special_005p = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Special-Rule-Thesis-005p-0.csv\", index_col=[0])\n",
    "maillist_special_005p = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Special-Rule-Thesis-005p-0.csv\", index_col=[0])\n",
    "sorting_special_005p = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Special-Rule-Thesis-005p-0.csv\", index_col=[0])\n",
    "\n",
    "# # Multi-Table test\n",
    "\n",
    "cacheprof_special_multi = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Special-Rule-Thesis-Multi-5P-0.csv\", index_col=[0])\n",
    "hidden_special_multi = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Special-Rule-Thesis-Multi-5P-0.csv\", index_col=[0])\n",
    "maillist_special_multi = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Special-Rule-Thesis-Multi-5P-0.csv\", index_col=[0])\n",
    "sorting_special_multi = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Special-Rule-Thesis-Multi-5P-0.csv\", index_col=[0])\n",
    "\n",
    "# # Multi-table 1% Test\n",
    "# cacheprof_special_multi_1p = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-PO-PAPER-SPECIAL-MULTI-RULE-1P-0.csv\", index_col=[0])\n",
    "# sorting_special_multi_1p = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-PO-PAPER-SPECIAL-MULTI-RULE-1P-0.csv\", index_col=[0])\n",
    "# maillist_special_multi_1p = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-PO-PAPER-SPECIAL-MULTI-RULE-1P-0.csv\", index_col=[0])\n",
    "# hidden_special_multi_1p = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-PO-PAPER-SPECIAL-MULTI-RULE-1P-0.csv\", index_col=[0])\n",
    "\n",
    "# # Multi-Threading Test\n",
    "# cacheprof_multi_thread = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-PCA_THREADING_TEST-0.csv\", index_col=[0])\n",
    "# sorting_multi_thread = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-PCA_THREADING_TEST-0.csv\", index_col=[0])\n",
    "# maillist_multi_thread = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-PCA_THREADING_TEST-0.csv\", index_col=[0])\n",
    "# hidden_multi_thread = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-PCA_THREADING_TEST-0.csv\", index_col=[0])\n",
    "\n",
    "# cacheprof_multi_thread_2 = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-PCA_THREADING_TEST_2-0.csv\", index_col=[0])\n",
    "# sorting_multi_thread_2 = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-PCA_THREADING_TEST_2-0.csv\", index_col=[0])\n",
    "# maillist_multi_thread_2 = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-PCA_THREADING_TEST_2-0.csv\", index_col=[0])\n",
    "# hidden_multi_thread_2 = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-PCA_THREADING_TEST_2-0.csv\", index_col=[0])\n",
    "\n",
    "# # Combined Test \n",
    "# cacheprof_combined = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Combined_Large_Features_Test-0.csv\", index_col=[0])\n",
    "# sorting_combined = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Combined_Large_Features_Test-0.csv\", index_col=[0])\n",
    "# maillist_combined = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Combined_Large_Features_Test-0.csv\", index_col=[0])\n",
    "# hidden_combined = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Combined_Large_Features_Test-0.csv\", index_col=[0])\n",
    "\n",
    "# # Large Features Test Combined 2\n",
    "# cacheprof_combined_2 = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Combined_Large_Features_Test_2-0.csv\", index_col=[0])\n",
    "# sorting_combined_2 = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Combined_Large_Features_Test_2-0.csv\", index_col=[0])\n",
    "# maillist_combined_2 = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Combined_Large_Features_Test_2-0.csv\", index_col=[0])\n",
    "# hidden_combined_2 = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Combined_Large_Features_Test_2-0.csv\", index_col=[0])\n",
    "\n",
    "# # Impactful Features 10% Test to see if it can still pick them all up\n",
    "# cacheprof_impact_10p = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Impactful_Features_Test_10p-0.csv\", index_col=[0])\n",
    "# sorting_impact_10p = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Impactful_Features_Test_10p-0.csv\", index_col=[0])\n",
    "# maillist_impact_10p = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Impactful_Features_Test_10p-0.csv\", index_col=[0])\n",
    "# hidden_impact_10p = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Impactful_Features_Test_10p-0.csv\", index_col=[0])\n",
    "\n",
    "# # Gini List Change\n",
    "# cacheprof_gini = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Gini_List_Sort_Removed_Test-0.csv\", index_col=[0])\n",
    "# sorting_gini = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Gini_List_Sort_Removed_Test-0.csv\", index_col=[0])\n",
    "# maillist_gini = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Gini_List_Sort_Removed_Test-0.csv\", index_col=[0])\n",
    "# hidden_gini = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Gini_List_Sort_Removed_Test-0.csv\", index_col=[0])\n",
    "\n",
    "# # Alternate Calc Test Using Random Forest Estimators instead of Decision Tree Estimators\n",
    "# cacheprof_alt = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Alternate_Impact_Calc_Test-0.csv\", index_col=[0])\n",
    "# sorting_alt = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Alternate_Impact_Calc_Test-0.csv\", index_col=[0])\n",
    "# maillist_alt = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Alternate_Impact_Calc_Test-0.csv\", index_col=[0])\n",
    "# hidden_alt = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Alternate_Impact_Calc_Test-0.csv\", index_col=[0])\n",
    "\n",
    "# # Decision Calc Test Using Single Threading\n",
    "# cacheprof_st_calc = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-SINGLE_THREAD_AFTER_IMPACT_CHANGE_SMALL-0.csv\", index_col=[0])\n",
    "# sorting_st_calc = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-SINGLE_THREAD_AFTER_IMPACT_CHANGE_SMALL-0.csv\", index_col=[0])\n",
    "# maillist_st_calc = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-SINGLE_THREAD_AFTER_IMPACT_CHANGE_SMALL-0.csv\", index_col=[0])\n",
    "# hidden_st_calc = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-SINGLE_THREAD_AFTER_IMPACT_CHANGE_SMALL-0.csv\", index_col=[0])\n",
    "\n",
    "\n",
    "# # Post-BugFix Mini-Test\n",
    "# cacheprof_bug = pd.read_csv(f\"{dir_path}/cacheprof-PHASEORDER-BOCA-Single_Threaded_After_BugFix-0.csv\", index_col=[0])\n",
    "# sorting_bug = pd.read_csv(f\"{dir_path}/sorting-PHASEORDER-BOCA-Single_Threaded_After_BugFix-0.csv\", index_col=[0])\n",
    "# maillist_bug = pd.read_csv(f\"{dir_path}/maillist-PHASEORDER-BOCA-Single_Threaded_After_BugFix-0.csv\", index_col=[0])\n",
    "# hidden_bug = pd.read_csv(f\"{dir_path}/hidden-PHASEORDER-BOCA-Single_Threaded_After_BugFix-0.csv\", index_col=[0])\n",
    "\n",
    "\n",
    "# slow_tables = {\"cacheprof\": cacheprof_slow, \"maillist\": maillist_slow, \"hidden\": hidden_slow, \"sorting\": sorting_slow}\n",
    "# fast_tables = tables = {\"cacheprof\": cacheprof_fast, \"maillist\": maillist_fast, \"hidden\": hidden_fast, \"sorting\": sorting_fast}\n",
    "program_tables = {\"cacheprof\": {\"BOCPA\": cacheprof_BOCA, \"RIO\": cacheprof_RIO, \"O2\": cacheprof_default}, \"sorting\": {\"BOCPA\": sorting_BOCA, \"RIO\": sorting_RIO, \"O2\": sorting_default}, \"hidden\": {\"BOCPA\": hidden_BOCA, \"RIO\":  hidden_RIO, \"O2\": hidden_default}, \"maillist\": {\"BOCPA\": maillist_BOCA, \"RIO\": maillist_RIO, \"O2\": maillist_default}}\n",
    "# program_tables_BOCA_Fixed = {\"cacheprof\": cacheprof_BOCA_Fixed , \"hidden\": hidden_BOCA_Fixed , \"maillist\": maillist_BOCA_Fixed , \"sorting\": sorting_BOCA_Fixed}\n",
    "correctness_tables = {\"cacheprof\": cacheprof_special, \"hidden\": hidden_special, \"maillist\": maillist_special, \"sorting\": sorting_special}\n",
    "correctness_tables_5p = {\"cacheprof\": cacheprof_special_5p, \"hidden\": hidden_special_5p, \"maillist\": maillist_special_5p, \"sorting\": sorting_special_5p}\n",
    "correctness_tables_1p = {\"cacheprof\": cacheprof_special_1p, \"hidden\": hidden_special_1p, \"maillist\": maillist_special_1p, \"sorting\": sorting_special_1p}\n",
    "correctness_tables_005p = {\"cacheprof\": cacheprof_special_005p, \"hidden\": hidden_special_005p, \"maillist\": maillist_special_005p, \"sorting\": sorting_special_005p}\n",
    "correctness_tables_multi = {\"cacheprof\": cacheprof_special_multi, \"hidden\": hidden_special_multi, \"maillist\": maillist_special_multi, \"sorting\": sorting_special_multi}\n",
    "# correctness_tables_multi_1p = {\"cacheprof\": cacheprof_special_multi_1p, \"hidden\": hidden_special_multi_1p, \"maillist\": maillist_special_multi_1p, \"sorting\": sorting_special_multi_1p}\n",
    "# multi_threading = {\"cacheprof\": cacheprof_multi_thread, \"hidden\": hidden_multi_thread, \"maillist\": maillist_multi_thread, \"sorting\": sorting_multi_thread}\n",
    "# multi_threading_2 = {\"cacheprof\": cacheprof_multi_thread_2, \"hidden\": hidden_multi_thread_2, \"maillist\": maillist_multi_thread_2, \"sorting\": sorting_multi_thread_2}\n",
    "# combined_test = {\"cacheprof\": cacheprof_combined, \"hidden\": hidden_combined, \"maillist\": maillist_combined, \"sorting\": sorting_combined}\n",
    "# combined_test_2 = {\"cacheprof\": cacheprof_combined_2, \"hidden\": hidden_combined_2, \"maillist\": maillist_combined_2, \"sorting\": sorting_combined_2}\n",
    "# impactful_10p = {\"cacheprof\": cacheprof_impact_10p, \"hidden\": hidden_impact_10p, \"maillist\": maillist_impact_10p, \"sorting\": sorting_impact_10p}\n",
    "# gini_tables = {\"cacheprof\": cacheprof_gini, \"hidden\": hidden_gini, \"maillist\": maillist_gini, \"sorting\": sorting_gini}\n",
    "# rf_tables = {\"cacheprof\": cacheprof_alt, \"hidden\": hidden_alt, \"maillist\": maillist_alt, \"sorting\": sorting_alt}\n",
    "# single_thread_calc = {\"cacheprof\": cacheprof_st_calc, \"hidden\": hidden_st_calc, \"maillist\": maillist_st_calc, \"sorting\": sorting_st_calc}\n",
    "# comparison_impact = {\"cacheprof\": cacheprof_BOCA_Fixed , \"hidden\": hidden_BOCA_Fixed , \"maillist\": maillist_BOCA_Fixed , \"sorting\": sorting_BOCA_Fixed}\n",
    "# tables_post_bugfix = {\"cacheprof\": cacheprof_bug , \"hidden\": hidden_bug , \"maillist\": maillist_bug , \"sorting\": sorting_bug}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64851335-2ec8-4205-9e63-d9304b9de49a",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b907b-b8b5-4660-a898-6c22c43e6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "O2_list = [\"liberate_case\",\"spec_constr\",\"rule_check2\",\"late_specialise\",\"triple_combo\",\"late_dmd_anal\",\"strict_anal\",\"rule_check3\",\"add_caller\",\"add_late\"] #, \"my_good_optimization\", \"my_neutral_optimization\", \"my_bad_optimization\", my_good_optimization_2, my_good_optimization_3, my_good_optimization_4, my_good_optimization_5, my_good_optimization_6]\n",
    "O0_list = [\"static_args\", \"presimplify\",\"specialise\",\"full_laziness_1\",\"simpl3\",\"float_in_1\",\"call_arity\",\"strictness\",\"exitification\",\"full_laziness_2\",\"cse\",\"float_in_2\",\"final\",\"rule_check1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567b335-355b-4467-b24b-cf388497e3f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Normalization & Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5196583-54ad-449d-88d2-6df503ee09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_tables = {}\n",
    "tick_labels = []\n",
    "\n",
    "for d_name, d in program_tables.items():\n",
    "    for type, t in d.items():\n",
    "        t[\"Norm-Z\"] = (t[\"Runtime\"] - t[\"Runtime\"].mean())/t[\"Runtime\"].std()\n",
    "        t.drop(columns=[\"Mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0f85e-51f8-4c36-b83e-0b905d7de81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_name, d in program_tables.items():\n",
    "    O2_numbers = program_tables[d_name][\"O2\"][\"Runtime\"].mean()\n",
    "    for type, t in d.items():\n",
    "        normalize_around = O2_numbers\n",
    "        offset = normalize_around - t[\"Runtime\"].mean()\n",
    "        t[\"Norm-Default\"] = (t[\"Runtime\"] - normalize_around)/t[\"Runtime\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a3802-da81-4bd0-b256-136733d38e4f",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887217b-abb1-4038-9e30-4aab2dd761ed",
   "metadata": {},
   "source": [
    "### Table (RIO vs. BOCPA vs. Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c0cd3-6b8e-4788-887f-b82c42498405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# THIS IS USING THE BEST RUNTIME\n",
    "\n",
    "data = []\n",
    "programs = list(program_tables.keys())\n",
    "configurations = [\"BOCPA\", \"RIO\"]\n",
    "columns = [\"Optimal\", \"Default\", \"Improvement\", \"Avg. Improvement\"]\n",
    "\n",
    "for program in programs:\n",
    "    program_data = []\n",
    "    row_O0s = []\n",
    "    row_O2s = []\n",
    "    for config in configurations:\n",
    "        if program_tables[program][config] is not None:\n",
    "            row_Optimal = round(program_tables[program][config].sort_values(\"Runtime\", ascending=True).iloc[0][\"Runtime\"],3)\n",
    "            row_Default = round(program_tables[program][\"O2\"][\"Runtime\"].mean(),3)\n",
    "            improvement = f\"{round(-1*(1 - row_Optimal/row_Default)*100,3)}%\"\n",
    "            average = f\"{round(-1*(1 - program_tables[program][config]['Runtime'].mean()/row_Default)*100,3)}%\"\n",
    "            program_data.append([row_Optimal, row_Default, improvement, average])\n",
    "            row_O0s.append(row_Optimal)\n",
    "            row_O2s.append(row_Default)\n",
    "        else:\n",
    "            program_data.append([None, None, None])\n",
    "    data.extend(program_data)\n",
    "    \n",
    "    # for config in configurations:\n",
    "    #     updated_program_tables[program][config][\"-O0\"][\"Runtime\"] = round(np.mean(row_O0s),3)\n",
    "    #     row_O2 = updated_program_tables[program][config][\"-O2\"][\"Runtime\"] = round(np.mean(row_O2s),3)\n",
    "\n",
    "# Create a MultiIndex with program and configuration levels\n",
    "index = pd.MultiIndex.from_product([programs, configurations], names=[\"Program\", \"Configuration\"])\n",
    "\n",
    "# print(index)\n",
    "# print(data)\n",
    "\n",
    "# Reshape data into a DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "# Assign the MultiIndex\n",
    "df.index = index\n",
    "\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"PO_table_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db58525-b88e-4a83-b7a3-eae5fa1fdfdb",
   "metadata": {},
   "source": [
    "### Box Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dcbfd4-3a57-443b-9b6a-6177d237af3c",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518a09d9-f6e7-4711-bb39-4b235f48ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Z_boxplot(program_name, tables_dict):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    for type_name, t in tables_dict[program_name].items():\n",
    "        if type_name != \"O2\":\n",
    "            lst1.append(t[\"Norm-Z\"])\n",
    "            labels.append(type_name)\n",
    "        \n",
    "    ax.boxplot(lst1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(f\"Normalized Z Runtime (std)\")\n",
    "    ax.set_xlabel(f\"Type of Optimization\")\n",
    "    ax.set_title(program_name)\n",
    "    \n",
    "    plt.savefig(f\"thesis_figures/PO_Z_{program_name}.png\", format=\"png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728f383-9902-4ac2-8aea-5c47d3a44f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Z_boxplot(\"cacheprof\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4339151-4b63-4aae-a776-bb0627ab0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Z_boxplot(\"sorting\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284808ca-3c39-44a3-bfb3-86062a7e3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Z_boxplot(\"hidden\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b55fec-914e-4f82-a46a-53a0911fc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Z_boxplot(\"maillist\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751bbc9-d37e-4fd7-bbc5-3029b03b5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "lst1 = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for program_name, type_dict in program_tables.items():\n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    O0_line = 0\n",
    "    for type_name, df in type_dict.items():\n",
    "        if type_name != \"O2\":\n",
    "            lst1.append(df[\"Norm-Z\"])\n",
    "            labels.append(type_name)\n",
    "        \n",
    "        # print(df.head(5))\n",
    "        # labels.append(type_name)\n",
    "        # #print(df[\"Norm-O2\"].head(4))\n",
    "        # # O0_line = df.loc[\"-O0\"][\"Norm-O2\"]\n",
    "        # lst1.append(df[\"Norm-O2\"])\n",
    "\n",
    "\n",
    "    \n",
    "    ax[i][j].boxplot(lst1)\n",
    "    ax[i][j].set_xticklabels(labels, fontsize=\"xx-small\")\n",
    "    ax[i][j].set_ylabel(f\"Normalized -O2 Runtime Distribution\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_xlabel(f\"Type of Optimization\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_title(f\"{program_name}\", fontsize=\"small\")\n",
    "\n",
    "    # ax[i][j].hlines(y=O0_line, xmin=0, xmax=len(labels) + 1, color='b', linestyle='dashed', linewidth=2)\n",
    "    # ax[i][j].text(len(labels) + 1.1, O0_line, '-O0', fontsize='xx-small', color='b')\n",
    "    \n",
    "    j = (j + 1) % 2\n",
    "    if j == 0:\n",
    "        i = (i + 1) % 2\n",
    "\n",
    "plt.savefig('thesis_figures/Z_PO_score_boxplot.png', format='png', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a807ad-baac-4ec5-b682-976c60dcb12e",
   "metadata": {},
   "source": [
    "#### O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f062d4-b7f4-49cd-9c66-76c20648d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make O2 Plot Function\n",
    "\n",
    "def make_O2_boxplot(program_name, hash_map):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    program_name = program_name\n",
    "    for type_name, t in hash_map[program_name].items():\n",
    "        if type_name != \"O2\":\n",
    "            lst1.append(t[\"Norm-Default\"])\n",
    "            labels.append(type_name)\n",
    "        \n",
    "    ax.boxplot(lst1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(f\"Normalized O2 Runtime (std)\")\n",
    "    ax.set_xlabel(f\"Type of Optimization\")\n",
    "    ax.set_title(f\"{program_name}\")\n",
    "    \n",
    "    plt.savefig(f\"PO_O2_{program_name}.png\", format=\"png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f0bff-682e-4cd0-951c-ff8a4f13bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_O2_boxplot(\"cacheprof\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216f3ea-d4c4-4571-b7fb-aaac51a850dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_O2_boxplot(\"cacheprof\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ecbfc-30f4-446c-b0e4-30234df1e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_O2_boxplot(\"maillist\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae09c3-540a-4ddc-bad5-c7cc7b5a73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_O2_boxplot(\"hidden\", program_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0dcea-4e8d-4d69-a9be-82552f359239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "lst1 = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for program_name, type_dict in program_tables.items():\n",
    "    lst1 = []\n",
    "    labels = []\n",
    "    O0_line = 0\n",
    "    for type_name, df in type_dict.items():\n",
    "        if type_name != \"O2\":\n",
    "            lst1.append(df[\"Norm-Default\"])\n",
    "            labels.append(type_name)\n",
    "        \n",
    "        # print(df.head(5))\n",
    "        # labels.append(type_name)\n",
    "        # #print(df[\"Norm-O2\"].head(4))\n",
    "        # # O0_line = df.loc[\"-O0\"][\"Norm-O2\"]\n",
    "        # lst1.append(df[\"Norm-O2\"])\n",
    "\n",
    "\n",
    "    \n",
    "    ax[i][j].boxplot(lst1)\n",
    "    ax[i][j].set_xticklabels(labels, fontsize=\"xx-small\")\n",
    "    ax[i][j].set_ylabel(f\"Normalized -O2 Runtime Distribution\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_xlabel(f\"Type of Optimization\", fontsize=\"x-small\")\n",
    "    ax[i][j].set_title(f\"{program_name}\", fontsize=\"small\")\n",
    "\n",
    "    # ax[i][j].hlines(y=O0_line, xmin=0, xmax=len(labels) + 1, color='b', linestyle='dashed', linewidth=2)\n",
    "    # ax[i][j].text(len(labels) + 1.1, O0_line, '-O0', fontsize='xx-small', color='b')\n",
    "    \n",
    "    j = (j + 1) % 2\n",
    "    if j == 0:\n",
    "        i = (i + 1) % 2\n",
    "\n",
    "plt.savefig('thesis_figures/O2_PO_score_boxplot.png', format='png', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc05ba-77d6-4115-afa9-c21d3b90826f",
   "metadata": {},
   "source": [
    "## BOCPA Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e31b22-8aa7-4274-b76f-c07ab9954255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_required_tuples(tuple_list):\n",
    "    for tup in  [(\"my_good_optimization\", \"my_neutral_optimization\"), (\"my_bad_optimization\", \"my_neutral_optimization\")]:\n",
    "        if tup in tuple_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def which_tuple(tuple_list):\n",
    "    if (\"my_good_optimization\", \"my_neutral_optimization\") in tuple_list and (\"my_bad_optimization\", \"my_neutral_optimization\") in tuple_list:\n",
    "        return \"Both\"\n",
    "    elif (\"my_good_optimization\", \"my_neutral_optimization\") in tuple_list:\n",
    "        return \"Good Only\"\n",
    "    elif (\"my_bad_optimization\", \"my_neutral_optimization\") in tuple_list:\n",
    "        return \"Bad Only\"\n",
    "    else:\n",
    "        return \"Neither\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bad88-02e4-4093-b7ef-618b29d3aa73",
   "metadata": {},
   "source": [
    "### Slow + Fast Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218c918-429e-4fe8-89ec-c966a161302a",
   "metadata": {},
   "source": [
    "#### Single Rule Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03976c-7a64-4c14-99a9-e240242497da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weird_apply(iteration, df, category):\n",
    "    training_set = df[df[\"Iteration\"] <= iteration]\n",
    "    total_size = training_set.count()\n",
    "    groups = training_set.groupby(\"Rules\")\n",
    "    both_rule = groups.size()[\"Both\"] if \"Both\" in groups.groups else 0\n",
    "    good_rule = groups.size()[\"Good Only\"] + both_rule if \"Good Only\" in groups.groups else 0\n",
    "    bad_rule = groups.size()[\"Bad Only\"] + both_rule if \"Bad Only\" in groups.groups else 0\n",
    "    good_rule = good_rule / total_size\n",
    "    bad_rule = bad_rule / total_size\n",
    "    if category == \"Good Only\":\n",
    "        return good_rule\n",
    "    else:\n",
    "        return bad_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68daac78-8231-4df1-846d-1afced8a507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discrimination_graph(dictionary, table_name, file_name):\n",
    "    fig, axes = plt.subplots(4, 1)\n",
    "    colors = [\"blue\", \"red\", \"purple\"]\n",
    "    # labels = [\"Both\", \"Slow\", \"Fast\"]\n",
    "    \n",
    "    # Scatter plot\n",
    "    \n",
    "    count = 0\n",
    "    handles = []  # Collect handles from all scatter plots\n",
    "    labels = []   # Collect labels from all scatter plots\n",
    "    for program_name, df in dictionary.items():\n",
    "        df_temp = df[[\"Iteration\", \"Rules\", \"Runtime\"]]\n",
    "        df_temp[\"Rules\"] = df_temp[\"Rules\"].apply(ast.literal_eval)\n",
    "        #filtered_df = df_temp[df_temp['Rules'].apply(has_required_tuples)]\n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df[\"Rules\"] = filtered_df[\"Rules\"].apply(which_tuple)\n",
    "    \n",
    "        filtered_df[\"PercentGood\"] = filtered_df[\"Iteration\"].apply(weird_apply, df=filtered_df, category=\"Good Only\")[\"Iteration\"]\n",
    "        filtered_df[\"PercentBad\"] = filtered_df[\"Iteration\"].apply(weird_apply, df=filtered_df, category=\"Bad Only\")[\"Iteration\"]\n",
    "        \n",
    "        count_2 = 0\n",
    "        filtered_df = filtered_df.sort_values(\"Rules\", ascending=True)\n",
    "        scatter = sns.lineplot(x=filtered_df[\"Iteration\"], y=filtered_df[\"PercentGood\"], color=sns.color_palette(\"husl\")[count % 4], sizes=(0, 10), label=program_name, ax=axes[count], legend=False)\n",
    "        scatter = sns.lineplot(x=filtered_df[\"Iteration\"], y=filtered_df[\"PercentBad\"], linestyle='--', color=sns.color_palette(\"husl\")[count % 4], sizes=(0, 10), label=program_name, ax=axes[count], legend=False)\n",
    "        handles.append(scatter.collections[0])  # Append handle for legend\n",
    "        labels.append(program_name)  # Append label for legend\n",
    "        count_2 += 1\n",
    "        \n",
    "        axes[count].set_title(None)\n",
    "        axes[count].set_xlabel(None)\n",
    "        axes[count].set_ylabel(None)\n",
    "        axes[count].set_yticks([i/4 for i in range(5)])\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Add labels and title\n",
    "\n",
    "    fig.supxlabel('Iteration')\n",
    "    fig.supylabel('% of Total Population')\n",
    "    fig.suptitle(table_name)\n",
    "    \n",
    "    # Show the legend\n",
    "    # handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.42, 0.01))\n",
    "    \n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], linestyle='-', color='k', label='Included Fast Rule'),\n",
    "        Line2D([0], [0], linestyle='--', color='k', label='Included Slow Rule')\n",
    "    ]\n",
    "    \n",
    "    fig.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.62, 0.01))\n",
    "    # plt.legend(title=\"Y-Values\", labels=[\"Value 0\", \"Value 1\", \"Value 2\"])\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'thesis_figures/{file_name}', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb496398-0d4f-4463-a340-2b6e2dcb0fe7",
   "metadata": {},
   "source": [
    "##### 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd21e75-abab-4911-b411-c5e16e9f2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_discrimination_graph(correctness_tables, \"Special Rule Inclusion (10%)\", 'Distribution_Scatter_Line.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a7d18-79c5-4b3f-ae44-1ba8dcab37c4",
   "metadata": {},
   "source": [
    "##### 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493c949-3469-4b35-9ae6-8609b63c324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_discrimination_graph(correctness_tables_5p, \"Special Rule Inclusion (5%)\", 'Distribution_Scatter_Line_5p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c703c-fbf9-4d9d-a53a-7cb0cfbbafea",
   "metadata": {},
   "source": [
    "##### 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61f731-c701-4a7a-943b-2442cd68f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_discrimination_graph(correctness_tables_1p, \"Special Rule Inclusion (1%)\", 'Distribution_Scatter_Line_1p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f2d77-ec11-41a9-80c2-6c52b6196196",
   "metadata": {},
   "source": [
    "##### 0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b705c4-e0d6-44d9-b225-12619797ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_discrimination_graph(correctness_tables_005p, \"Special Rule Inclusion (0.5%)\", 'Distribution_Scatter_Line_005p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db160aaf-16f9-4091-8550-1cf089899fb5",
   "metadata": {},
   "source": [
    "### Impactful Collection of Arbitrary Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b740ead-88ec-4bd2-b477-b2466b1f7d0f",
   "metadata": {},
   "source": [
    "#### Function Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b97153-6be2-41c4-ba3f-8ec670b04248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_required_tuples_multi(tuple_list):\n",
    "    for tup in  [(\"my_good_optimization\", \"my_neutral_optimization\"), (\"my_good_optimization_2\", \"my_neutral_optimization\"), (\"my_good_optimization_3\", \"my_neutral_optimization\"), (\"my_good_optimization_4\", \"my_neutral_optimization\"), (\"my_good_optimization_5\", \"my_neutral_optimization\"), (\"my_good_optimization_6\", \"my_neutral_optimization\")]:\n",
    "        if tup in tuple_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def which_tuple_multi(tuple_list):\n",
    "    intersection_list = list(set(tuple_list).intersection(set([(\"my_good_optimization\", \"my_neutral_optimization\"), (\"my_good_optimization_2\", \"my_neutral_optimization\"), (\"my_good_optimization_3\", \"my_neutral_optimization\"), (\"my_good_optimization_4\", \"my_neutral_optimization\"), (\"my_good_optimization_5\", \"my_neutral_optimization\"), (\"my_good_optimization_6\", \"my_neutral_optimization\")])))\n",
    "    return len(intersection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e4e12-dc13-4bd1-a002-8c0c8ba7a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds Cummulative Test for Rules (NOT IMPACT LIST)\n",
    "def build_cummulative_rule_graph(dictionary, graph_title, file_name):\n",
    "    fig, axes = plt.subplots(4, 1)\n",
    "    colors = [\"blue\", \"red\", \"purple\"]\n",
    "    # labels = [\"Both\", \"Slow\", \"Fast\"]\n",
    "    \n",
    "    # Scatter plot\n",
    "    \n",
    "    count = 0\n",
    "    handles = []  # Collect handles from all scatter plots\n",
    "    labels = []   # Collect labels from all scatter plots\n",
    "    for program_name, df in dictionary.items():\n",
    "        df_temp = df[[\"Iteration\", \"Rules\", \"Runtime\"]]\n",
    "        df_temp[\"Rules\"] = df_temp[\"Rules\"].apply(ast.literal_eval)\n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df[\"Rules\"] = filtered_df[\"Rules\"].apply(which_tuple_multi)\n",
    "        filtered_df[\"Rules\"] = filtered_df[\"Rules\"]/6\n",
    "        filtered_df[\"PercentCollected\"] = filtered_df[\"Rules\"]\n",
    "        \n",
    "        count_2 = 0\n",
    "        filtered_df = filtered_df.sort_values(\"Rules\", ascending=True)\n",
    "        scatter = sns.lineplot(x=filtered_df[\"Iteration\"], y=filtered_df[\"PercentCollected\"], color=sns.color_palette(\"husl\")[count % 4], sizes=(0, 10), label=program_name, ax=axes[count], legend=False)\n",
    "        handles.append(scatter.collections[0])  # Append handle for legend\n",
    "        labels.append(program_name)  # Append label for legend\n",
    "        count_2 += 1\n",
    "            \n",
    "        # Set custom y-axis labels\n",
    "        \n",
    "        axes[count].set_title(None)\n",
    "        axes[count].set_xlabel(None)\n",
    "        axes[count].set_ylabel(None)\n",
    "        ticks = [i/6 for i in range(7)]\n",
    "        tick_labels = [f'{i}/6' for i in range(7)]\n",
    "        \n",
    "        axes[count].set_yticks(ticks)\n",
    "        axes[count].set_yticklabels(tick_labels)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Add labels and title\n",
    "    fig.supxlabel('Iteration')\n",
    "    fig.supylabel('Number of Rules Collected in Candidate')\n",
    "    fig.suptitle(graph_title)\n",
    "    \n",
    "    # Show the legend\n",
    "    # handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.42, 0.01))\n",
    "    \n",
    "    \n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'thesis_figures/{file_name}', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de871f31-08b3-4128-abeb-b60c32397965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds Cummulative Test for Impact List (NOT RULE LIST)\n",
    "def build_cummulative_impact_graph(dictionary, graph_title, file_name):\n",
    "    fig, axes = plt.subplots(4, 1)\n",
    "    colors = [\"blue\", \"red\", \"purple\"]\n",
    "    # labels = [\"Both\", \"Slow\", \"Fast\"]\n",
    "    \n",
    "    # Scatter plot\n",
    "    count = 0\n",
    "    handles = []  # Collect handles from all scatter plots\n",
    "    labels = []   # Collect labels from all scatter plots\n",
    "    for program_name, df in dictionary.items():\n",
    "        df_temp = df[[\"Iteration\", \"Rules\", \"Impactful Rules\", \"Runtime\"]].dropna()\n",
    "        df_temp[\"Rules\"] = df_temp[\"Rules\"].apply(ast.literal_eval)\n",
    "        df_temp[\"Impactful Rules\"] = df_temp[\"Impactful Rules\"].apply(ast.literal_eval)\n",
    "        \n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df[\"Impactful Rules\"] = filtered_df[\"Impactful Rules\"].apply(which_tuple_multi)\n",
    "        filtered_df[\"Impactful Rules\"] = filtered_df[\"Impactful Rules\"]/6\n",
    "        filtered_df[\"PercentCollected\"] = filtered_df[\"Impactful Rules\"]\n",
    "        \n",
    "        count_2 = 0\n",
    "        filtered_df = filtered_df.sort_values(\"Rules\", ascending=True)\n",
    "        scatter = sns.lineplot(x=filtered_df[\"Iteration\"], y=filtered_df[\"PercentCollected\"], color=sns.color_palette(\"husl\")[count % 4], sizes=(0, 10), label=program_name, ax=axes[count], legend=False)\n",
    "        handles.append(scatter.collections[0])  # Append handle for legend\n",
    "        labels.append(program_name)  # Append label for legend\n",
    "        count_2 += 1\n",
    "            \n",
    "        # Set custom y-axis labels\n",
    "        axes[count].set_title(None)\n",
    "        axes[count].set_xlabel(None)\n",
    "        axes[count].set_ylabel(None)\n",
    "        ticks = [i/6 for i in range(7)]\n",
    "        tick_labels = [f'{i}/6' for i in range(7)]\n",
    "        \n",
    "        axes[count].set_yticks(ticks)\n",
    "        axes[count].set_yticklabels(tick_labels)\n",
    "        \n",
    "        # Adjust y-axis limits to prevent clipping of markers\n",
    "        count += 1\n",
    "    \n",
    "    # Add labels and title\n",
    "    fig.supxlabel('Iteration')\n",
    "    fig.supylabel('Number of Rules Collected in Candidate')\n",
    "    fig.suptitle(graph_title)\n",
    "    \n",
    "    # Show the legend\n",
    "    fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.42, 0.01))\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'thesis_figures/{file_name}', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d98745-52c1-43d5-b71d-fd90f5431b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line of Best Fit Through Rules (Not Impact List)\n",
    "def build_cummulative_graph_reg(dictionary, graph_title, file_name):\n",
    "    fig, axes = plt.subplots(4, 1)\n",
    "    colors = [\"blue\", \"red\", \"purple\"]\n",
    "    \n",
    "    count = 0\n",
    "    handles = []  # Collect handles from all scatter plots\n",
    "    labels = []   # Collect labels from all scatter plots\n",
    "    for program_name, df in dictionary.items():\n",
    "        df_temp = df[[\"Iteration\", \"Rules\", \"Impactful Rules\", \"Runtime\"]].dropna()\n",
    "        df_temp[\"Rules\"] = df_temp[\"Rules\"].apply(ast.literal_eval)\n",
    "        \n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df = df_temp.copy()\n",
    "        filtered_df[\"Rules\"] = filtered_df[\"Rules\"].apply(which_tuple_multi)\n",
    "        filtered_df[\"Rules\"] = filtered_df[\"Rules\"]/6\n",
    "        filtered_df[\"PercentCollected\"] = filtered_df[\"Rules\"]\n",
    "        \n",
    "        count_2 = 0\n",
    "        filtered_df = filtered_df.sort_values(\"Rules\", ascending=True)\n",
    "        scatter = sns.regplot(x=filtered_df[\"Iteration\"], y=filtered_df[\"PercentCollected\"], color=sns.color_palette(\"husl\")[count % 4], label=program_name, ax=axes[count])\n",
    "        handles.append(scatter.collections[0])  # Append handle for legend\n",
    "        labels.append(program_name)  # Append label for legend\n",
    "        count_2 += 1\n",
    "            \n",
    "        # Set custom y-axis labels\n",
    "        axes[count].set_title(None)\n",
    "        axes[count].set_xlabel(None)\n",
    "        axes[count].set_ylabel(None)\n",
    "        ticks = [i/6 for i in range(7)]\n",
    "        tick_labels = [f'{i}/6' for i in range(7)]\n",
    "        \n",
    "        axes[count].set_yticks(ticks)\n",
    "        axes[count].set_yticklabels(tick_labels)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Add labels and title\n",
    "    fig.supxlabel('Iteration')\n",
    "    fig.supylabel('Number of Rules Collected in Candidate')\n",
    "    fig.suptitle(graph_title)\n",
    "    \n",
    "    # Show the legend\n",
    "    fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.42, 0.01))\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'thesis_figures/{file_name}', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a4fb7-69f2-49b0-a341-78a571b52d41",
   "metadata": {},
   "source": [
    "#### Multi-Rule Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89a426-3012-4bf9-bf89-b75f987b5d13",
   "metadata": {},
   "source": [
    "##### Cummulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd2f6e-38fa-42fc-9d6b-955f9b645c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cummulative_rule_graph(correctness_tables_multi, \"Cummulative Rule Collection in Candidate (5%/ea)\",  'Cumm_Rule_Collect_5p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b8088-85d2-4613-a1f5-515ccba54640",
   "metadata": {},
   "source": [
    "##### Cummulation Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5d83b-79d1-4cad-8679-d8564d615b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cummulative_graph_reg(correctness_tables_multi, \"Cummulative Rule Collection in Candidate (5%/ea) - Regression Plot\",  'Cumm_Rule_Collect_REG_5p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0622b-e8dd-42b5-8430-edc780ce49bc",
   "metadata": {},
   "source": [
    "##### Cummulation Impact List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a5ee6-af2e-44a1-884c-adb028ebf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cummulative_impact_graph(correctness_tables_multi, \"Cummulative Rule Collection in Impact List (5%/ea)\",  'Cumm_Rule_Collect_Impact_5p.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82671c-6443-4ea3-ab7f-20d694f1d5f6",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421fc34-8fb5-46ac-aa28-e1f0152bfa83",
   "metadata": {},
   "source": [
    "### MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fa835-2a73-47c1-8c4c-952db28abb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = O0_list + O2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ceec25-b75d-426d-bf0e-286c3f71a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_possible_rules():\n",
    "    all_rules = []\n",
    "    for opt_A in combined_list:\n",
    "        for opt_B in combined_list:\n",
    "            if opt_A != opt_B:\n",
    "                all_rules.append((opt_A, opt_B))\n",
    "    return all_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01897167-4ccc-404c-9e59-fdb668a87a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_possible_valid_rules():\n",
    "    # Uses the movable optimization list to create possible pairs. Does not touch the invalid list.\n",
    "    all_rules = []\n",
    "    for opt_A in O2_list:\n",
    "        for opt_B in O2_list:\n",
    "            if opt_A != opt_B:\n",
    "                all_rules.append((opt_A, opt_B))\n",
    "    return all_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54f40f-c8ae-438a-ae9a-114401084966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_BOCA_rules(order_array):\n",
    "    # Creates rules for orderings. For example (\"A\", \"B\") => \"A must go before B\"\n",
    "    if (len(combined_list) != len(order_array)):\n",
    "        raise ValueError(f\"What the hell?: Combined List: {len(combined_list)}, Order List: {len(order_array)} \\n {order_array}\")\n",
    "    rules_list = []\n",
    "    blank_list = [None] * (len(combined_list))\n",
    "    for index, optimization in enumerate(combined_list):\n",
    "        pos_num = int(order_array[index])\n",
    "        blank_list[pos_num] = optimization\n",
    "    for index, opt_A in enumerate(blank_list):\n",
    "        for opt_B in blank_list[index:]:\n",
    "            if opt_A != opt_B:\n",
    "                rules_list.append((opt_A, opt_B))\n",
    "    return rules_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2e67f-42ff-44b6-b5f2-b3df617bbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_phase_order(phase_order):\n",
    "    return list(filter(lambda x: x != '', phase_order.split(\"|\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f0c25-39fc-43f4-801a-4df51079fea1",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1cfe5-267c-4f6b-933a-92f7d8a58a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_tables = program_tables.copy()\n",
    "\n",
    "all_rules = generate_all_possible_rules()\n",
    "\n",
    "feature_df = pd.DataFrame(columns=all_rules + [\"Runtime\"])\n",
    "scaled_data = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for program_name, config_dict in scaling_tables.items():\n",
    "    for config, df in config_dict.items():\n",
    "        df[\"Phase\"] = df[\"Phase\"].apply(split_phase_order)\n",
    "        df[\"Phase\"] = df[\"Phase\"].apply(generate_BOCA_rules)\n",
    "        new_rows = []\n",
    "        for index, row in df.iterrows():\n",
    "            # Initialize a list to hold flag values for this row\n",
    "            rule_values = [0] * len(all_rules)\n",
    "            \n",
    "            # Iterate through each flag in the row\n",
    "            #print(row['Flags'])\n",
    "            for index, rule in enumerate(row.Phase):\n",
    "                # Find the index of the flag in my_flags and set the corresponding value to 1\n",
    "                if rule in all_rules:\n",
    "                    rule_values[all_rules.index(rule)] = 1\n",
    "                \n",
    "            # Append the row to the new DataFrame with flag values and Runtime\n",
    "            new_rows.append(rule_values + [None])\n",
    "        scaling=StandardScaler()\n",
    "        scaling.fit(np.array(df[\"Runtime\"]).reshape(-1, 1))\n",
    "        scaled_data=scaling.transform(np.array(df[\"Runtime\"]).reshape(-1, 1))\n",
    "        for index, row in enumerate(new_rows):\n",
    "            row[len(row) - 1] = scaled_data[index][0]\n",
    "        new_df = pd.DataFrame(columns=feature_df.columns, data=new_rows)\n",
    "        feature_df = pd.concat([feature_df, new_df], axis=0)\n",
    "        \n",
    "\n",
    "# scaling=StandardScaler()\n",
    " \n",
    "# # Use fit and transform method \n",
    "# scaling.fit(np.array(feature_df[\"Runtime\"]).reshape(-1, 1))\n",
    "# scaled_data=scaling.transform(np.array(feature_df[\"Runtime\"]).reshape(-1, 1))\n",
    "\n",
    "feature_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4d423-d59c-4fc0-96b8-f1b02d74a085",
   "metadata": {},
   "source": [
    "#### MCA Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd570bf7-be08-4ed8-b5d7-d4e6b4e7c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_df.columns:\n",
    "    feature_df[col] = pd.to_numeric(feature_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c3679-35e8-4797-95f7-2fdba3f3e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = MCA(n_components=2)\n",
    "mca.fit(feature_df.drop(\"Runtime\",axis=1))\n",
    "print(\"Eigenvalues:\")\n",
    "print(mca.eigenvalues_)\n",
    "\n",
    "\n",
    "\n",
    "# Transformed data\n",
    "print(\"Transformed Data:\")\n",
    "transformed_data = mca.transform(feature_df.drop(\"Runtime\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786f1b3-f7af-47d4-a618-4180ea560edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd04be-bc41-497f-bae3-8a97080469f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row and column coordinates (normalized singular values) after fitting\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "column_coordinates = mca.column_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "\n",
    "# Calculate the variance explained by each feature after using 6 components\n",
    "variance_explained_by_feature = (column_coordinates ** 2).sum(axis=1)\n",
    "\n",
    "# Sort the features based on their contribution to the variance\n",
    "top_features = variance_explained_by_feature.sort_values(ascending=False)\n",
    "\n",
    "# Print the top 6 features\n",
    "print(\"Top 6 features contributing the most to the variance after using 6 components:\")\n",
    "top_features.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa142b-7c60-403b-a8ab-72d382a9e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.column_contributions_.style.format('{:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84910427-ae71-4fc2-b4ed-b61e4f81b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\",axis=1))\n",
    "row_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ae1f3-259e-48c8-bdf2-1af200046cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style with a warm and nuanced color palette\n",
    "sns.set(style=\"whitegrid\", palette=\"rocket\")\n",
    "\n",
    "# Get the row coordinates (coordinates of categories) for the first two components\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"Runtime\", axis=1))\n",
    "\n",
    "# Plot the row coordinates on a scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot points for Component 0 with circles\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][0:len(row_coordinates)//2], \n",
    "                y=row_coordinates.iloc[:, 1][0:len(row_coordinates)//2], \n",
    "                alpha=0.7, label='Component 0', marker='o')\n",
    "\n",
    "# Plot points for Component 1 with squares\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][len(row_coordinates)//2:], \n",
    "                y=row_coordinates.iloc[:, 1][len(row_coordinates)//2:], \n",
    "                alpha=0.7, label='Component 1', marker='s')\n",
    "\n",
    "plt.title('MCA Plot of Components')\n",
    "plt.xlabel('Component 0')\n",
    "plt.ylabel('Component 1')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.savefig('thesis_figures/PO_MCA_2d_plot.svg', format='svg', dpi=1200)\n",
    "plt.savefig('thesis_figures/PO_MCA_2d_plot.png', format='png', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbb45b-e92d-44ab-84e9-19e8ec823b9f",
   "metadata": {},
   "source": [
    "### MCA = Impactful Features from BOCPA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ff454-bd23-4507-9547-a5c822e1e3e1",
   "metadata": {},
   "source": [
    "#### Counter Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238c73b-e03d-449d-ae3b-929be7306098",
   "metadata": {},
   "outputs": [],
   "source": [
    "impactful_entries = []\n",
    "\n",
    "counter_tables = program_tables.copy()\n",
    "\n",
    "for program_name, tables in counter_tables.items():\n",
    "    for model, t in tables.items():\n",
    "        top_entries_t = []\n",
    "        if model == \"BOCPA\":\n",
    "            t = t.dropna()\n",
    "            t['Impactful Rules'] = t['Impactful Rules'].apply(ast.literal_eval)\n",
    "            # df_sorted = t.sort_values(\"Runtime\", ascending=True)\n",
    "            impactful_entries.append(list(t[\"Impactful Rules\"]))\n",
    "            # impactful_entries.append(list(df_sorted[df_sorted[\"Runtime\"] <= program_tables[program_name][\"O2\"][\"Runtime\"].mean()][\"Impactful Rules\"]))\n",
    "\n",
    "tuple_count_per_program = []\n",
    "\n",
    "for program in impactful_entries:\n",
    "    flat_list = list(set([item for sublist in program for item in sublist]))\n",
    "    tuple_count_per_program.append(Counter(flat_list))\n",
    "\n",
    "big_counter = Counter()\n",
    "\n",
    "for program_counter in tuple_count_per_program:\n",
    "    big_counter += program_counter\n",
    "\n",
    "top_counter_10 = big_counter.most_common(10)\n",
    "\n",
    "print(\"Top 10 Elements:\")\n",
    "for element, count in top_counter_10:\n",
    "    print(f\"{element},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de01d1-14ee-4d80-a1f5-a12bd9d9e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a68377-2b42-4ddf-a4ec-9b953a84d0ce",
   "metadata": {},
   "source": [
    "### MCA to Predict Working Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ae5c4-c661-41ed-b886-db33945457d6",
   "metadata": {},
   "source": [
    "#### MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50003ff1-51e4-419c-8842-09ebf43a3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = phase_data.copy()\n",
    "feature_df = pd.DataFrame(columns=all_rules + [\"worked\"])\n",
    "scaled_data = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "new_table[\"phase\"] = new_table[\"phase\"].apply(split_phase_order)\n",
    "new_table[\"phase\"] = new_table[\"phase\"].apply(generate_BOCA_rules)\n",
    "new_rows = []\n",
    "for index, row in new_table.iterrows():\n",
    "    # Initialize a list to hold flag values for this row\n",
    "    rule_values = [0] * len(all_rules)\n",
    "    \n",
    "    # Iterate through each flag in the row\n",
    "    #print(row['Flags'])\n",
    "    for index, rule in enumerate(row.phase):\n",
    "        # Find the index of the flag in my_flags and set the corresponding value to 1\n",
    "        if rule in all_rules:\n",
    "            rule_values[all_rules.index(rule)] = 1\n",
    "        \n",
    "    # Append the row to the new DataFrame with flag values and Runtime\n",
    "    new_rows.append(rule_values + [row.worked])\n",
    "    \n",
    "new_df = pd.DataFrame(columns=feature_df.columns, data=new_rows)\n",
    "feature_df = pd.concat([feature_df, new_df], axis=0)\n",
    "\n",
    "feature_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad4076-26c2-4c64-b823-491db6d5bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_df.columns:\n",
    "    feature_df[col] = pd.to_numeric(feature_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7997849-41fb-45e9-b75c-e9603e0bce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = MCA(n_components=2)\n",
    "mca.fit(feature_df.drop(\"worked\",axis=1))\n",
    "print(\"Eigenvalues:\")\n",
    "print(mca.eigenvalues_)\n",
    "\n",
    "\n",
    "\n",
    "# Transformed data\n",
    "print(\"Transformed Data:\")\n",
    "transformed_data = mca.transform(feature_df.drop(\"worked\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afae9d9-29c7-434c-ae92-2e61c32dc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8319243-48d8-44d8-ab8a-864ca1043e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row and column coordinates (normalized singular values) after fitting\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"worked\",axis=1))\n",
    "column_coordinates = mca.column_coordinates(feature_df.drop(\"worked\",axis=1))\n",
    "\n",
    "# Calculate the variance explained by each feature after using 6 components\n",
    "variance_explained_by_feature = (column_coordinates ** 2).sum(axis=1)\n",
    "\n",
    "# Sort the features based on their contribution to the variance\n",
    "top_features = variance_explained_by_feature.sort_values(ascending=False)\n",
    "\n",
    "# Print the top 6 features\n",
    "print(\"Top 6 features contributing the most to the variance after using 6 components:\")\n",
    "top_features.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7693ab7-ea96-46d3-b467-15c75339e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mca.column_contributions_.style.format('{:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf24bd-1783-434e-9529-8d4717f91404",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"worked\",axis=1))\n",
    "row_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a252f9-a0ae-46b0-8060-4bdc8e0ce16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style with a warm and nuanced color palette\n",
    "sns.set(style=\"whitegrid\", palette=\"rocket\")\n",
    "\n",
    "# Get the row coordinates (coordinates of categories) for the first two components\n",
    "row_coordinates = mca.row_coordinates(feature_df.drop(\"worked\", axis=1))\n",
    "\n",
    "# Plot the row coordinates on a scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot points for Component 0 with circles\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][0:len(row_coordinates)//2], \n",
    "                y=row_coordinates.iloc[:, 1][0:len(row_coordinates)//2], \n",
    "                alpha=0.7, label='Component 0', marker='o')\n",
    "\n",
    "# Plot points for Component 1 with squares\n",
    "sns.scatterplot(x=row_coordinates.iloc[:, 0][len(row_coordinates)//2:], \n",
    "                y=row_coordinates.iloc[:, 1][len(row_coordinates)//2:], \n",
    "                alpha=0.7, label='Component 1', marker='s')\n",
    "\n",
    "plt.title('MCA Plot of Components')\n",
    "plt.xlabel('Component 0')\n",
    "plt.ylabel('Component 1')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.savefig('thesis_figures/PO_Worked_MCA_2d_plot.svg', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a6f56-9311-4a03-8066-649394491768",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac718e-30ce-45de-a0a3-383c46107e77",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310ed89-5703-484f-ac1f-50a076f121c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "classification_set = phase_data.copy()\n",
    "\n",
    "\n",
    "classification_set = phase_data.drop(\"worked\",axis=1)\n",
    "\n",
    "classification_set[\"phase\"] = classification_set[\"phase\"].apply(split_phase_order)\n",
    "classification_set[\"phase\"] = classification_set[\"phase\"].apply(generate_BOCA_rules)\n",
    "new_rows = []\n",
    "for index, row in classification_set.iterrows():\n",
    "    # Initialize a list to hold flag values for this row\n",
    "    rule_values = [0] * len(all_rules)\n",
    "    \n",
    "    # Iterate through each flag in the row\n",
    "    #print(row['Flags'])\n",
    "    for index, rule in enumerate(row.phase):\n",
    "        # Find the index of the flag in my_flags and set the corresponding value to 1\n",
    "        if rule in all_rules:\n",
    "            rule_values[all_rules.index(rule)] = 1\n",
    "        \n",
    "    # Append the row to the new DataFrame with flag values and Runtime\n",
    "    new_rows.append(rule_values)\n",
    "    \n",
    "classification_set = pd.DataFrame(columns=all_rules, data=new_rows)\n",
    "#classification_set = pd.concat([feature_df, new_df], axis=0)\n",
    "\n",
    "classification_set.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e04b0-a621-4ed1-b078-f986534289f3",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbe657-d27f-41d6-977a-8c4244df885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classification_set\n",
    "y = phase_data[\"worked\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "transformed_candidates = pd.DataFrame(columns=all_rules)\n",
    "\n",
    "# Predict using the classifier\n",
    "predict = clf.predict(X_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7eb600-9dc4-4149-9aad-d6733e44e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predict))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, predict))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4318270-6da8-4957-b579-0846cc7f31cb",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3ca94-9e30-452e-a718-1e95b3a26ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28caf4-c8fe-459f-be4d-b44e6f578206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# Plotting our two-features-space\n",
    "\n",
    "#print((list(X_train)[3])[0])\n",
    "sns.scatterplot(x=X_train[:, 4], \n",
    "                y=X_train[:, 27], \n",
    "                hue=y_train, \n",
    "                s=8);\n",
    "# Constructing a hyperplane using a formula.\n",
    "w = clf.coef_[0]           # w consists of 2 elements\n",
    "b = clf.intercept_[0]      # b consists of 1 element\n",
    "x_points = np.linspace(-1, 1)    # generating x-points from -1 to 1\n",
    "y_points = -(w[0] / w[1]) * x_points - b / w[1]  # getting corresponding y-points\n",
    "# Plotting a red hyperplane\n",
    "plt.plot(x_points, y_points, c='r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f9240-2780-45fa-ab2a-74951a4e9f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
